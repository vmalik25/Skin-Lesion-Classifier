{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "215cd460",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "from deap import base, creator, tools, algorithms\n",
    "import random\n",
    "import cv2  \n",
    "from skimage import color\n",
    "from skimage import io\n",
    "from skimage import morphology\n",
    "from skimage import transform\n",
    "from skimage import util\n",
    "from skimage.feature import greycomatrix\n",
    "from skimage.filters import threshold_otsu\n",
    "from skimage.restoration import inpaint\n",
    "from skimage import color, io, transform, util, feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1889e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('HAM10000_metadata.csv')  # Replace 'your_dataset.csv' with your actual dataset\n",
    "\n",
    "image_directory = 'PycharmProjects/pythonProject/data/all_images'  # Replace with the actual path to your image directory\n",
    "\n",
    "# Combine directory path with image file names to create full paths\n",
    "df['image_path_column'] = os.path.join(image_directory, df['image_id'])\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['image_path_column'], df['dx'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Balancing the training set using Random Oversampling\n",
    "oversampler = RandomOverSampler(random_state=42)\n",
    "X_train_resampled, y_train_resampled = oversampler.fit_resample(X_train.to_frame(), y_train)\n",
    "\n",
    "# Convert resampled DataFrame back to Series\n",
    "X_train_resampled = X_train_resampled.squeeze()\n",
    "y_train_resampled = pd.Series(y_train_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2b819ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(image_path, target_size=(512, 512)):\n",
    "    \n",
    "    img = cv2.imread(image_path)\n",
    "    img_resized = cv2.resize(img, target_size)\n",
    "    img_no_hair = remove_hair(img_resized)\n",
    "    img_smoothed = remove_noise(img_no_hair)\n",
    "\n",
    "    return img_smoothed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e647c719",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_hair(image):\n",
    "\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    black_hat = cv2.morphologyEx(gray, cv2.MORPH_BLACKHAT, kernel)\n",
    "    _, mask = cv2.threshold(black_hat, 10, 255, cv2.THRESH_BINARY)\n",
    "    inpainted_image = cv2.inpaint(image, mask, inpaintRadius, flags=cv2.INPAINT_TELEA)\n",
    "\n",
    "    return inpainted_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fe4e21ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_noise(image, kernel_size=7):\n",
    "\n",
    "    img_smoothed = cv2.GaussianBlur(image, (kernel_size, kernel_size), 0)\n",
    "\n",
    "    return img_smoothed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c7df490a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def automatic_grabcut(image):\n",
    "    \n",
    "    hsv_image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "    green_mask = extract_green_color_mask(hsv_image)\n",
    "    threshold = compute_mask_threshold(green_mask)\n",
    "    if np.sum(green_mask) > threshold:\n",
    "        rectangle = generate_rectangle(image)\n",
    "        grabcut_result = grabcut_segmentation(image, rectangle)\n",
    "    else:\n",
    "        grabcut_result = grabcut_segmentation(image, green_mask)\n",
    "\n",
    "    return grabcut_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3480cddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_green_color_mask(hsv_image):\n",
    "\n",
    "    lower_green = np.array([40, 40, 40])\n",
    "    upper_green = np.array([80, 255, 255])\n",
    "    green_mask = cv2.inRange(hsv_image, lower_green, upper_green)\n",
    "    green_mask = green_mask // 255  \n",
    "\n",
    "    return green_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b93974e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_mask_threshold(mask):\n",
    "\n",
    "    image_area = mask.size\n",
    "    mask_area = np.sum(mask)\n",
    "    threshold = 0.7 * image_area  \n",
    "\n",
    "    return threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "89b82474",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_rectangle(image):\n",
    "\n",
    "    Hr = int(image.shape[0] - 0.3 * image.shape[0])\n",
    "    Wr = int(image.shape[1] - 0.3 * image.shape[1])\n",
    "    rectangle = np.zeros(image.shape[:2], dtype=np.uint8)\n",
    "    rectangle[:Hr, :Wr] = 1\n",
    "\n",
    "    return rectangle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "12b633c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grabcut_segmentation(image, mask):\n",
    "\n",
    "    bgd_model = np.zeros((1, 65), dtype=np.float64)\n",
    "    fgd_model = np.zeros((1, 65), dtype=np.float64)\n",
    "    rect = (0, 0, image.shape[1], image.shape[0])\n",
    "    cv2.grabCut(image, mask, rect, bgd_model, fgd_model, 5, cv2.GC_INIT_WITH_MASK)\n",
    "    grabcut_mask = np.where((mask == 2) | (mask == 0), 0, 1).astype('uint8')\n",
    "\n",
    "    grabcut_result = image * grabcut_mask[:, :, np.newaxis]\n",
    "\n",
    "    return grabcut_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bd04d649",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_glcm_features(image):\n",
    "    gray_image = color.rgb2gray(image)\n",
    "    gray_image = img_as_ubyte(gray_image)\n",
    "\n",
    "    distances = [1, 2, 3]\n",
    "    angles = [0, np.pi/4, np.pi/2, 3*np.pi/4]\n",
    "\n",
    "    glcm = greycomatrix(gray_image, distances=distances, angles=angles, symmetric=True, normed=True)\n",
    "\n",
    "    contrast = np.sum(glcm[:, :, 0, 0] * (np.arange(0, glcm.shape[0]) - np.arange(0, glcm.shape[0])).reshape(-1, 1))\n",
    "    energy = np.sum(glcm[:, :, 0, 0] ** 2)\n",
    "    entropy = -np.sum(glcm[:, :, 0, 0] * np.log(glcm[:, :, 0, 0] + 1e-10))\n",
    "    correlation = np.sum(((np.arange(0, glcm.shape[0]) - np.mean(np.arange(0, glcm.shape[0]))) / np.std(np.arange(0, glcm.shape[0]))) * \\\n",
    "                          ((np.arange(0, glcm.shape[0]) - np.mean(np.arange(0, glcm.shape[0]))) / np.std(np.arange(0, glcm.shape[0]))).reshape(-1, 1) * glcm[:, :, 0, 0])\n",
    "    homogeneity = np.sum(glcm[:, :, 0, 0] / (1 + np.abs(np.arange(0, glcm.shape[0]) - np.arange(0, glcm.shape[0])).reshape(-1, 1)))\n",
    "\n",
    "    return contrast, energy, entropy, correlation, homogeneity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f3f5ad8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_statistical_features(image):\n",
    "    mean_values = np.mean(image, axis=(0, 1))\n",
    "    variance_values = np.var(image, axis=(0, 1))\n",
    "    std_dev_values = np.std(image, axis=(0, 1))\n",
    "    rms_values = np.sqrt(np.mean(image ** 2, axis=(0, 1)))\n",
    "\n",
    "    return mean_values, variance_values, std_dev_values, rms_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c188be9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(image):\n",
    "    glcm=extract_glcm_features(image)\n",
    "    stats=extract_statistical_features(image)\n",
    "    return np.concatenate([glcm,stats])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1ccf94bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: imbalanced-learn in c:\\users\\predator\\anaconda3\\lib\\site-packages (0.10.1)\n",
      "Collecting imbalanced-learn\n",
      "  Downloading imbalanced_learn-0.11.0-py3-none-any.whl (235 kB)\n",
      "     ---------------------------------------- 0.0/235.6 kB ? eta -:--:--\n",
      "     -------------------------------------- 235.6/235.6 kB 7.3 MB/s eta 0:00:00\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\predator\\anaconda3\\lib\\site-packages (from imbalanced-learn) (1.1.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\predator\\anaconda3\\lib\\site-packages (from imbalanced-learn) (2.2.0)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\predator\\anaconda3\\lib\\site-packages (from imbalanced-learn) (1.24.3)\n",
      "Requirement already satisfied: scipy>=1.5.0 in c:\\users\\predator\\anaconda3\\lib\\site-packages (from imbalanced-learn) (1.10.1)\n",
      "Requirement already satisfied: scikit-learn>=1.0.2 in c:\\users\\predator\\anaconda3\\lib\\site-packages (from imbalanced-learn) (1.2.2)\n",
      "Installing collected packages: imbalanced-learn\n",
      "  Attempting uninstall: imbalanced-learn\n",
      "    Found existing installation: imbalanced-learn 0.10.1\n",
      "    Uninstalling imbalanced-learn-0.10.1:\n",
      "      Successfully uninstalled imbalanced-learn-0.10.1\n",
      "Successfully installed imbalanced-learn-0.11.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -U imbalanced-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cd34808f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f45ea659",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting deapNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "  Downloading deap-1.4.1-cp39-cp39-win_amd64.whl (109 kB)\n",
      "     ---------------------------------------- 0.0/109.9 kB ? eta -:--:--\n",
      "     ---------------------------------------- 109.9/109.9 kB ? eta 0:00:00\n",
      "Requirement already satisfied: numpy in c:\\users\\predator\\anaconda3\\lib\\site-packages (from deap) (1.24.3)\n",
      "Installing collected packages: deap\n",
      "Successfully installed deap-1.4.1\n"
     ]
    }
   ],
   "source": [
    "pip install deap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "85d4ffc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deap import base, creator, tools, algorithms\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6d2037be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_classifier(individual, classifier, param_grid):\n",
    "    params = {param: individual[i] for i, param in enumerate(param_grid)}\n",
    "    classifier.set_params(**params)\n",
    "    classifier.fit(X_train, y_train)\n",
    "    predictions = classifier.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "    return accuracy,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "323a40be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_toolbox(param_grid):\n",
    "    creator.create(\"FitnessMax\", base.Fitness, weights=(1.0,))\n",
    "    creator.create(\"Individual\", list, fitness=creator.FitnessMax)\n",
    "    toolbox = base.Toolbox()\n",
    "    toolbox.register(\"individual\", tools.initCycle, creator.Individual, param_grid, n=1)\n",
    "    toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n",
    "    toolbox.register(\"mate\", tools.cxBlend, alpha=0.5)\n",
    "    toolbox.register(\"mutate\", tools.mutGaussian, mu=0, sigma=1, indpb=0.2)\n",
    "    toolbox.register(\"select\", tools.selTournament, tournsize=3)\n",
    "    toolbox.register(\"evaluate\", optimize_classifier, classifier=classifier, param_grid=param_grid)\n",
    "    return toolbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a0f02be",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_param_grid = {'n_neighbors': [3, 5, 7]}\n",
    "knn_classifier = KNeighborsClassifier()\n",
    "knn_toolbox = create_toolbox(knn_param_grid)\n",
    "_, best_params = algorithms.eaSimple(knn_toolbox.population(n=10), knn_toolbox, cxpb=0.7, mutpb=0.2, ngen=5, stats=None, halloffame=None, verbose=True)\n",
    "knn_classifier.set_params(**{param: best_params[i] for i, param in enumerate(knn_param_grid)})\n",
    "knn_classifier.fit(X_train, y_train)\n",
    "knn_predictions = knn_classifier.predict(X_test)\n",
    "knn_accuracy = accuracy_score(y_test, knn_predictions)\n",
    "print(f\"KNN Accuracy: {knn_accuracy}, Best Parameters: {best_params[0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5582ef95",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_param_grid = {'C': [0.1, 1, 10], 'kernel': ['linear', 'rbf']}\n",
    "svm_classifier = SVC()\n",
    "svm_toolbox = create_toolbox(svm_param_grid)\n",
    "_, best_params = algorithms.eaSimple(svm_toolbox.population(n=10), svm_toolbox, cxpb=0.7, mutpb=0.2, ngen=5, stats=None, halloffame=None, verbose=True)\n",
    "svm_classifier.set_params(**{param: best_params[i] for i, param in enumerate(svm_param_grid)})\n",
    "svm_classifier.fit(X_train, y_train)\n",
    "svm_predictions = svm_classifier.predict(X_test)\n",
    "svm_accuracy = accuracy_score(y_test, svm_predictions)\n",
    "print(f\"SVM Accuracy: {svm_accuracy}, Best Parameters: {best_params[0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b70ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_param_grid = {'max_depth': [None, 5, 10]}\n",
    "dt_classifier = DecisionTreeClassifier()\n",
    "dt_toolbox = create_toolbox(dt_param_grid)\n",
    "_, best_params = algorithms.eaSimple(dt_toolbox.population(n=10), dt_toolbox, cxpb=0.7, mutpb=0.2, ngen=5, stats=None, halloffame=None, verbose=True)\n",
    "dt_classifier.set_params(**{param: best_params[i] for i, param in enumerate(dt_param_grid)})\n",
    "dt_classifier.fit(X_train, y_train)\n",
    "dt_predictions = dt_classifier.predict(X_test)\n",
    "dt_accuracy = accuracy_score(y_test, dt_predictions)\n",
    "print(f\"Decision Tree Accuracy: {dt_accuracy}, Best Parameters: {best_params[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fede3eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for image_path, label in zip(X_test, y_test):\n",
    "    # Preprocess image\n",
    "    processed_image = preprocess_image(image_path)\n",
    "\n",
    "    # Hair Removal\n",
    "    hair_removed_image = remove_hair(processed_image)\n",
    "\n",
    "    # Image Resizing\n",
    "    resized_image = resize_image(hair_removed_image)\n",
    "\n",
    "    # Segmentation\n",
    "    segmented_image = segmentation(resized_image)\n",
    "\n",
    "    # Feature Extraction\n",
    "    features = extract_features(segmented_image)\n",
    "\n",
    "    # Classification\n",
    "    knn_prediction = knn_classifier.predict([features])[0]\n",
    "    svm_prediction = svm_classifier.predict([features])[0]\n",
    "    dt_prediction = dt_classifier.predict([features])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f9755ab3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: h5py in c:\\users\\predator\\anaconda3\\lib\\site-packages (3.7.0)\n",
      "Requirement already satisfied: numpy>=1.14.5 in c:\\users\\predator\\anaconda3\\lib\\site-packages (from h5py) (1.24.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "50a654f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: joblib in c:\\users\\predator\\anaconda3\\lib\\site-packages (1.1.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "933908fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e11fccae",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_model_filename = 'model.h5'\n",
    "with h5py.File(svm_model_filename, 'w') as hf:\n",
    "    for key, value in svm_classifier.__dict__.items():\n",
    "        if isinstance(value, np.ndarray):\n",
    "            hf.create_dataset(key, data=value)\n",
    "        elif isinstance(value, list):\n",
    "            hf.create_dataset(key, data=np.array(value))\n",
    "        elif isinstance(value, (int, float)):\n",
    "            hf.create_dataset(key, data=value)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
